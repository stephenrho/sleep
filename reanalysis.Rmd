---
title: "Reanalysis of Greco et al. (2022, *Sleep*)"
author:
  - Stephen Rhodes^[steverho89@gmail.com]
date: "Last updated: `r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

Greco et al. (2022), in the "Statement of significance" section, claim that their findings suggest that "[...] wearing an eye mask during sleep is an effective, economical, and noninvasive behavior that could benefit cognitive function and lead to measurable impacts on everyday life." Here we examine some of the analysis choices made in this article and critically assess this claim. Firstly, Greco et al. should be applauded for clearly stating their analysis model and for publicly sharing their data (https://osf.io/q4p9v/), which made this reanalysis possible.

In Experiment 1, paired associates learning (PAL) was assessed on day 6 and 7 of the manipulation (eye mask or control), following 5 nights of habituation. On day 6 participants learned words paired to particular cue words up to a 60% correct criterion. The first test of PAL was then 10 minutes later with the number of correctly recalled words (out of 80) being the outcome. The second PAL assessment occurred on day 7 with no additional learning opportunities in between. The two PAL assessments were split up and analyzed separately via the following mixed effects model (using syntax from the `lme4` package for `R`):
```
lmer(y ~ eye_mask + (1 | ID) + (1 | year), data = data, REML = FALSE)
```
where `y` is the outcome of interest, `year` was a factor with two levels representing changes in the nature of the control condition from 2018 to 2019, and `eye_mask` refers to whether or not participants had worn an eye mask (1 = yes, 0 = no) in the 5 or 6 nights prior to testing. 

Using this model there was a significant difference in the average number of words recalled between mask and control on day 6. However, these conditions did not differ in terms of an 'absolute consolidation' score, which was the difference in performance between days 6 and 7 (reported in the supplement).[^msl]

[^msl]: It is interesting to note that a similar overnight change analysis is presented for the motor skill learning task in the supplement but the main article reports an analysis in which the interaction of condition and day was tested for this outcome.

It is not clear why the day 6 and 7 results were separated, as performance on the PAL task could have been assessed via a single model. Indeed a single model analysis is preferable if the difference between immediate and delayed recall is of interest. Splitting the data to assess a 'mask effect' obviously inflates the type i error rate. A more appropriate model would have also allowed for an interaction between `year` and `eye_mask` as changing the nature of the control condition may have influenced the *difference* between the control and eye mask conditions, which is encoded in the fixed effect for `eye_mask`. Including `year` as a random effect only allows for overall performance to vary by `year` of study. Further, as year only has two levels, it seems inappropriate to try to estimate a variance component for this factor and, as we found when recreating the analysis, there were situations where this caused fit issues in the reported analysis (the 'singular fit' warning from `lme4`).

As participants were assessed under both the control and eye mask conditions, assessing the PAL data as a whole allows one to model between participant variability in the size of the eye mask effect (i.e., a random slope term for `eye_mask`). Not accounting for this source of variability in the model is important as the standard errors for the fixed effect of `eye_mask` will be too small, leading to incorrect p-values, and, potentially, incorrect decisions as to whether to reject the null hypothesis of no difference (Barr et al., 2013).

We reanalyzed the PAL data with the following model, which allows for a interaction between condition (`eye_mask`) and year, to account for the different control conditions, and an interaction between condition and day, which codes whether the assessment was on day 6 (immediate) or day 7 (delayed).[^reml]
```
 lmer(y ~ eye_mask + year + day + eye_mask:year + eye_mask:day + 
             (1 + eye_mask + day | ID), 
           data = pal1, REML = FALSE) 
```

[^reml]: We have set `REML=FALSE` to fit the model via maximum likelihood, rather than restricted maximum likelihood (REML). This is to match Greco et al., who used ML to allow for a likelihood ratio test. However, `REML=TRUE` would likely lead to better estimates of fixed effect standard errors.

In this analysis the coefficient for `eye_mask` is not significantly different from zero ($b$ = 0.99 [-0.01, 2.00], $p$ = 0.053).[^stz] Further, the interactions between condition and year or day are not significant. There is also no significant eye mask vs control condition main effect in a mixed models ANOVA, which, unlike the above model, includes all two way and the three way interactions ($F$(1, 81) = 3.77, $p$ = 0.056). 

[^stz]: `year` and `day` were 'sum-to-zero' coded so that the `eye_mask` fixed effect can be directly interpreted as an 'overall' eye mask effect.

We also reanalyzed average reaction times from the psychomotor vigilance test (PVT) via a mixed model that allowed for a fixed effect interaction between year and condition, as well as a participant-level random intercept and slope for the difference between eye mask and control. The difference between conditions is significantly different from zero, albeit with greater uncertainty in the magnitude of the difference, $b$ = -6.239 [-12.363, -0.115], $p$ = 0.047.

For the data from Experiment 2, it is not possible to estimate a random participant slope for eye mask as there was only one score per condition. Greco et al. also note that this experiment was not powered to detect differences in PAL or PVT scores, as the goal was to assess correlations with electrophysiological measures (see supplement to article). Nevertheless, we recreated the results for both tasks but found that the number of unique participant IDs in the data files was lower (N = 28) than that reported in the article (N = 33 following exclusions).

So what are we to make of the effects of eye masks on cognition? When reassessing the data presented with more appropriate models we find less consistent evidence for cognitive effects of wearing an eye mask. However, this reanalysis should also be interpreted with caution. Information on condition order was not available in the data files and is potentially important given that some participants were omitted from analysis, thereby possibly leading to an imbalanced design. Further, the participant-level data from the PVT are average reaction times from an unspecified number of trials where responses could be missing due to overly short or long response times. Trial level data would allow one to take into account these additional sources of variation/uncertainty. 

Even if we were to take these improved estimates at face value it is difficult to imagine how being able to, on average, remember 0 to 2 (the 95% CI around the `eye_mask` effect) extra words out of 80 or being able to respond 0.1 to 12 milliseconds faster after wearing an eye mask could lead to measurable impacts on everyday life.

(1180 words)

# References

Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. *Journal of memory and language, 68*(3), 255-278.

Greco, V., Bergamo, D., Cuoccio, P., Konkoly, K. R., Lombardo, K. M., & Lewis, P. A. (2022). Wearing an eye mask during overnight sleep improves episodic learning and alertness. *Sleep*, online ahead of print. https://doi.org/10.1093/sleep/zsac305

\newpage

# Code for Reanalysis

Additional code for results not presented here is available at https://github.com/stephenrho/sleep/blob/main/reanalysis.Rmd

```{r setup, include=T}
knitr::opts_chunk$set(echo = T, warning = F, message = F)

library(data.table)
library(ggplot2)
library(lme4)
library(lmerTest)
library(afex)

theme_set(theme_bw())

# get the data
proj_url = "https://osf.io/q4p9v/"

if (!dir.exists("data/")){
  library(osfr)
  dir.create("data/")
  osf = osf_retrieve_node(proj_url)
  osf_download(osf_ls_files(osf), recurse = T, path = "data/") 
}

readdat <- function(file){
  # reshape the data
  exp = ifelse(grepl("Experiment1", file), 1, 2)
  
  if (exp == 1){
    dat = readxl::read_xlsx(file, skip = 1)
    
    stopifnot(all(colnames(dat) == c('Participants', 'YearOfExperiment', 
                                     'Eyemask...3', 'ControlMask...4', 
                                     'Eyemask...5', 'ControlMask...6')))
    
    dv_cols = paste(
      rep(c("Eyemask", "Control"), 2), 
      rep(c("day6", "day7"), each = 2), 
      sep = "_"
    )
    
    colnames(dat)[3:6] = dv_cols
  } else{
    dat = readxl::read_xlsx(file)
    
    stopifnot(all(colnames(dat) == c('Participants', 'YearOfExperiment', 
                                     'Eyemask', 'ControlMask')))
    dv_cols = c("Eyemask", "Control")
    colnames(dat)[3:4] = dv_cols
  }
  
  colnames(dat)[2] = "year"
  
  dat$ID = paste(dat$Participants, dat$year, sep = "_")
  # wide to long
  d = reshape2::melt(dat, id.vars = c("ID", "year"), measure.vars = dv_cols, variable.name = "condition", value.name = "y")
  
  d$eye_mask = as.numeric(grepl("Eyemask", d$condition))
  
  if (exp == 1){
    d$day = ifelse(grepl("day7", d$condition), "day 7", "day 6")
    d$day = as.factor(d$day)
    d$condition = gsub("_day6|_day7", "", d$condition)
  }
  
  d$condition = as.factor(d$condition)
  d$year = as.factor(d$year)
  
  return(d)
}

pal1 = readdat("data/Tasks&Questionnaire/PAL/PAL_Experiment1.xlsx")
pvt1 = readdat("data/Tasks&Questionnaire/PVT/PVT_Experiment1.xlsx")
msl1 = readdat("data/Tasks&Questionnaire/MSL/MSL_Experiment1.xlsx")

pal2 = readdat("data/Tasks&Questionnaire/PAL/PAL_Experiment2.xlsx")
pvt2 = readdat("data/Tasks&Questionnaire/PVT/PVT_Experiment2.xlsx")
```

## Paired associates learning

```{r PAL}
### PAL (primary outcome) ----
length(unique(pal1$ID))

ggplot(pal1, aes(x = condition, y=y, group=ID)) + 
  geom_line(alpha=1/2) + 
  stat_summary(aes(x = condition, y=y, group=1), 
               fun="mean", geom="line", inherit.aes = F, 
               lwd=3, col="red") +
  #facet_wrap(~day) + 
  facet_grid(year ~ day) +
  labs(x="Condition", y="PAL score", title="Experiment 1")

aggregate(y ~ eye_mask, data = subset(pal1, day == "day 6"), FUN = mean)
aggregate(y ~ eye_mask, data = subset(pal1, day == "day 7"), FUN = mean)
aggregate(y ~ eye_mask, data = pal1, FUN = mean)

# original model
lmer(y ~ eye_mask + (1 | ID) + (1 | year), data = subset(pal1, day == "day 6"), 
     REML = FALSE) |>
  summary()

# analysis reported in supplement
pal1w = reshape2::dcast(pal1, formula = ... ~ day, value.var = "y")
pal1w$y = pal1w$`day 6` - pal1w$`day 7`

lmer(y ~ eye_mask + (1 | ID) + (1 | year), data = pal1w, 
     REML = FALSE) |>
  summary()

# note: in both cases there is a singular fit warning
# most likely trying to estimate random effect for 2 groups...

# more appropriate model
# (1) analyze the data from the PAL task as a whole.
# no need to separate days.
# (2) account for ID level variability in difference 
# between eye mask and control
# (3) year = different control conditions, so should account 
# for *interaction* between eye mask and year 
# doesn't make sense to include year as random effect

# make contrast for year and day sum to zero so coefficient 
# for mask is at 'average' year
contrasts(pal1$year) = c(-1,1)
contrasts(pal1$day) = c(-1,1) 
mod = lmer(y ~ eye_mask + year + day + eye_mask:year + eye_mask:day + 
             (1 + eye_mask + day | ID), 
           data = pal1, REML = FALSE) 

summary(mod)
confint(mod)
# some warnings but profile plots/zeta diagrams look ok 
# https://stackoverflow.com/questions/74018300/warnings-when-computing-confidence-intervals-using-confint-for-linear-growth-mod
# pp = profile(mod)
# lattice::xyplot(pp)

# mixed ANOVA (note: tests extra interactions)
aov_car(y ~ condition*year*day + Error(ID/(condition*day)), 
        data = pal1, fun_aggregate = mean)

# Experiment 2
# n unique IDs don't match N = 33 reported in paper
length(unique(pal2$ID))

aggregate(y ~ condition, pal2, mean)
# the means match though...

ggplot(pal2, aes(x = condition, y=y, group=ID)) + 
  geom_line(alpha=1/2) + 
  stat_summary(aes(x = condition, y=y, group=1), 
               fun="mean", geom="line", inherit.aes = F, 
               lwd=3, col="red") +
  labs(x="Condition", y="PAL score", title="Experiment 2")

# recreate original analysis
mod = lmer(y ~ eye_mask + (1  | ID), data = pal2, REML = F)

summary(mod)
confint(mod)

aov_car(y ~ condition + Error(ID/condition), data = pal2, fun_aggregate = mean)

```

## Psychomotor vigilance test

```{r PVT}
### PVT ----
length(unique(pvt1$ID))

ggplot(pvt1, aes(x = condition, y=y, group=ID)) + 
  geom_line(alpha=1/2) + 
  stat_summary(aes(x = condition, y=y, group=1), 
               fun="mean", geom="line", inherit.aes = F, 
               lwd=3, col="red") +
  #facet_wrap(~day) + 
  facet_grid(year ~ day) +
  labs(x="Condition", y="PVT RT (ms)", title="Experiment 1")

# this matches reported means (but figure 2b means look different?)
aggregate(y ~ eye_mask, data = pvt1, FUN = mean)

# original model
lmer(y ~ eye_mask + (1 | ID) + (1 | year), data = pvt1, REML = FALSE) |>
  summary()
# note: boundary (singular) fit: see help('isSingular') 

# more appropriate model
contrasts(pvt1$year) = c(-1,1)
mod = lmer(y ~ eye_mask*year + (1 + eye_mask | ID), data = pvt1, REML = FALSE) 

summary(mod)
confint(mod)

# mixed ANOVA (averages day 6 and 7)
aov_car(y ~ condition*year + Error(ID/condition), 
        data = pvt1, fun_aggregate = mean)

# Experiment 2
# also 28, not 33
length(unique(pvt2$ID))

ggplot(pvt2, aes(x = condition, y=y, group=ID)) + 
  geom_line(alpha=1/2) + 
  stat_summary(aes(x = condition, y=y, group=1), 
               fun="mean", geom="line", inherit.aes = F, 
               lwd=3, col="red") +
  labs(x="Condition", y="PVT RT (ms)", title="Experiment 2")

aggregate(y ~ condition, pvt2, mean)

aov_car(y ~ condition + Error(ID/condition), data = pvt2, fun_aggregate = mean)

lmer(y ~ eye_mask + (1  | ID), data = pvt2, REML = F) |>
  summary()

```

```{r MSL, include=F}
# Motor-Skill Learning

# change include to T above to include this analysis

### MSL ----
length(unique(msl1$ID))

ggplot(msl1, aes(x = condition, y=y, group=ID)) + 
  geom_line(alpha=1/2) + 
  stat_summary(aes(x = condition, y=y, group=1), 
               fun="mean", geom="line", inherit.aes = F, 
               lwd=3, col="red") +
  #facet_wrap(~day) + 
  facet_grid(year ~ day) +
  labs(x="Condition", y="MSL Score", title="Experiment 1")

aggregate(y ~ eye_mask, data = msl1, FUN = mean)

# original model
lmer(y ~ eye_mask + (1 | ID) + (1 | year), data = msl1, REML = FALSE) |>
  summary()

# actually this is the model reported...
lmer(y ~ eye_mask*day + (1 | ID) + (1 | year), data = msl1, REML = FALSE) |>
  summary()
# interpretation in the paper is that people get 
# better after sleep. Also probably practice

# more appropriate model
lmer(y ~ eye_mask*year + (1 + eye_mask | ID), data = msl1, REML = FALSE) |>
  summary()

# mixed ANOVA (averages day 6 and 7)
aov_car(y ~ condition*year + Error(ID/condition), data = msl1, fun_aggregate = mean)
```

